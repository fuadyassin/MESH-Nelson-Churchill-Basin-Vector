{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3871556-5a72-4f80-a366-825f99334b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from owslib.ogcapi.features import Features\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d94e6fb2-0203-4c05-a82d-89ac648df9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Features API\n",
    "oafeat = Features(\"https://api.weather.gc.ca/\")\n",
    "\n",
    "def create_date_range(start_date, end_date):\n",
    "    return pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "def extract_flow_data_us(station_list, start_date, end_date):\n",
    "    dates = create_date_range(start_date, end_date)\n",
    "    empty_df = pd.DataFrame({'Date': dates})\n",
    "    station_info = []\n",
    "\n",
    "    for station in station_list:\n",
    "        empty_df[station] = np.nan\n",
    "    \n",
    "    for station in station_list:\n",
    "        url = f\"https://waterservices.usgs.gov/nwis/dv/?format=json&sites={station}&startDT={start_date}&endDT={end_date}&parameterCd=00060&statCd=00003\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'timeSeries' in data['value']:\n",
    "                records = data['value']['timeSeries'][0]['values'][0]['value']\n",
    "                flow_data = pd.DataFrame(records)\n",
    "                flow_data['value'] = pd.to_numeric(flow_data['value'], errors='coerce')\n",
    "                flow_data['dateTime'] = pd.to_datetime(flow_data['dateTime']).dt.date\n",
    "                flow_data['dateTime'] = flow_data['dateTime'].astype(str)\n",
    "                empty_df['Date'] = empty_df['Date'].astype(str)\n",
    "                for date, flow in zip(flow_data['dateTime'], flow_data['value']):\n",
    "                    empty_df.loc[empty_df['Date'] == date, station] = flow\n",
    "                \n",
    "                # Collect station information\n",
    "                site_info = data['value']['timeSeries'][0]['sourceInfo']\n",
    "                station_info.append({\n",
    "                    'Station_Number': site_info['siteCode'][0]['value'],\n",
    "                    'Station_Name': site_info['siteName'],\n",
    "                    'Latitude': site_info['geoLocation']['geogLocation']['latitude'],\n",
    "                    'Longitude': site_info['geoLocation']['geogLocation']['longitude'],\n",
    "                    'Drainage_Area': next((prop['value'] for prop in site_info['siteProperty'] if prop['name'] == 'drain_area_va'), None)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Flow data column not found for station: {station}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for station: {station}\")\n",
    "    \n",
    "    return empty_df, station_info\n",
    "\n",
    "def fetch_hydrometric_data_ca(station_numbers, start_date, end_date, limit=500):\n",
    "    combined_data = pd.DataFrame({'Date': create_date_range(start_date, end_date)})\n",
    "    station_info = []\n",
    "\n",
    "    for station_number in station_numbers:\n",
    "        offset = 0\n",
    "        full_data = []\n",
    "\n",
    "        while True:\n",
    "            url = f\"https://api.weather.gc.ca/collections/hydrometric-daily-mean/items\"\n",
    "            params = {\n",
    "                'STATION_NUMBER': station_number,\n",
    "                'datetime': f\"{start_date}/{end_date}\",\n",
    "                'limit': limit,\n",
    "                'offset': offset,\n",
    "                'f': 'json'\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, params=params)\n",
    "            response_data = response.json()\n",
    "\n",
    "            if 'features' in response_data and response_data['features']:\n",
    "                full_data.extend(response_data['features'])\n",
    "                offset += limit\n",
    "                if len(response_data['features']) < limit:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if full_data:\n",
    "            # Create data_list with dates and discharge values\n",
    "            data_list = [\n",
    "                {\n",
    "                    'Date': feature['properties']['DATE'],\n",
    "                    'value': feature['properties']['DISCHARGE'] if feature['properties']['DISCHARGE'] is not None else -1000\n",
    "                }\n",
    "                for feature in full_data\n",
    "            ]\n",
    "\n",
    "            # Convert data_list to DataFrame\n",
    "            flow_data = pd.DataFrame(data_list)\n",
    "\n",
    "            # Convert 'value' to numeric and 'Date' to datetime.date\n",
    "            flow_data['value'] = pd.to_numeric(flow_data['value'], errors='coerce')\n",
    "            flow_data['Date'] = pd.to_datetime(flow_data['Date']).dt.date\n",
    "            flow_data['Date'] = flow_data['Date'].astype(str)\n",
    "            combined_data['Date'] = combined_data['Date'].astype(str)\n",
    "\n",
    "            # Create a new column for the station in combined_data\n",
    "            combined_data[station_number] = np.nan\n",
    "\n",
    "            # Populate combined_data with flow data\n",
    "            for date, flow in zip(flow_data['Date'], flow_data['value']):\n",
    "                combined_data.loc[combined_data['Date'] == date, station_number] = flow\n",
    "\n",
    "            # Collect station information\n",
    "            first_feature = full_data[0]['properties']\n",
    "            geometry = full_data[0]['geometry']\n",
    "            station_info.append({\n",
    "                'Station_Number': first_feature['STATION_NUMBER'],\n",
    "                'Station_Name': first_feature['STATION_NAME'],\n",
    "                'Latitude': geometry['coordinates'][1],\n",
    "                'Longitude': geometry['coordinates'][0],\n",
    "                'Drainage_Area': first_feature.get('DRAINAGE_AREA_GROSS', None)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Flow data not found for station: {station_number}\")\n",
    "\n",
    "    return combined_data, station_info\n",
    "\n",
    "def write_flow_data_to_file_obstxt(file_path, flow_data, site_details):\n",
    "    # Replace NaN with -1.000\n",
    "    flow_data = flow_data.fillna(-1.000)\n",
    "    \n",
    "    # Convert Date column to datetime\n",
    "    flow_data['Date'] = pd.to_datetime(flow_data['Date'])\n",
    "\n",
    "    # Prepare the text file\n",
    "    with open(file_path, \"w\") as file_conn:\n",
    "        # Write header line\n",
    "        start_date = flow_data['Date'].min()\n",
    "        end_date = flow_data['Date'].max()\n",
    "        file_conn.write(f\"Observedstreamflow\\t{start_date.strftime('%Y/%m/%d')}\\t{end_date.strftime('%Y/%m/%d')}\\n\")\n",
    "        \n",
    "        # Write second line\n",
    "        num_stations = flow_data.shape[1] - 1\n",
    "        num_days = flow_data.shape[0]\n",
    "        start_year = start_date.strftime('%Y')\n",
    "        start_day_of_year = start_date.timetuple().tm_yday\n",
    "        file_conn.write(f\"{num_stations}  {num_days}  {num_days}  24 {start_year}  {start_day_of_year} 00\\n\")\n",
    "        \n",
    "        # Write station metadata with integer lat*60 and lon*60\n",
    "        for station_id in flow_data.columns[1:]:\n",
    "            station_info = next((item for item in site_details if item[\"Station_Number\"] == station_id), None)\n",
    "            if station_info:\n",
    "                lat = station_info['Latitude']\n",
    "                lon = station_info['Longitude']\n",
    "                drainage_area = station_info['Drainage_Area']\n",
    "                if drainage_area is None:\n",
    "                    drainage_area = -1.0\n",
    "                station_name = station_info['Station_Name']\n",
    "                file_conn.write(f\"{int(lat * 60):4d} {int(lon * 60):4d} {lat:12.6f} {lon:12.6f} {station_id:12s} {float(drainage_area):12.3f} {station_name}\\n\")\n",
    "        \n",
    "        # Write flow data with 12.4 decimal format\n",
    "        for i in range(num_days):\n",
    "            flow_values = flow_data.iloc[i, 1:].values  # Exclude the Date column\n",
    "            formatted_flow_values = \" \".join(f\"{x:12.4f}\" for x in flow_values)\n",
    "            file_conn.write(f\"{formatted_flow_values}\\n\")\n",
    "            \n",
    "def write_flow_data_to_file_ensim(file_path, flow_data, site_details):\n",
    "    # Replace NaN with -1.000\n",
    "    flow_data = flow_data.fillna(-1.000)\n",
    "    \n",
    "    # Define header components\n",
    "    header = [\n",
    "        \"########################################\",\n",
    "        \":FileType tb0  ASCII  EnSim 1.0\",\n",
    "        \"#\",\n",
    "        \"# DataType               Time Series\",\n",
    "        \"#\",\n",
    "        \":Application             EnSimHydrologic\",\n",
    "        \":Version                 2.1.23\",\n",
    "        \":WrittenBy          PythonScript\",\n",
    "        f\":CreationDate       {datetime.now().strftime('%Y-%m-%d')}\",\n",
    "        \"#\",\n",
    "        \"#---------------------------------------\",\n",
    "        \":SourceFile                   flow_data\",\n",
    "        \"#\",\n",
    "        \":Name               streamflow\",\n",
    "        \"#\",\n",
    "        \":Projection         LATLONG\",\n",
    "        \":Ellipsoid          WGS84\",\n",
    "        \"#\",\n",
    "        f\":StartTime          {flow_data['Date'].iloc[0]} 00:00:00.00000\",\n",
    "        \"#\",\n",
    "        \":AttributeUnits            1.0000000\",\n",
    "        \":DeltaT               24\",\n",
    "        \":RoutingDeltaT         1\",\n",
    "        \"#\",\n",
    "        \":ColumnMetaData\",\n",
    "        f\"   :ColumnUnits             {' '.join(['m3/s' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        f\"   :ColumnType             {' '.join(['float' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        f\"   :ColumnName           {' '.join(flow_data.columns[1:])}\",\n",
    "        \"   :ColumnLocationX    \" + ' '.join([f\"{site['Longitude'] * 60:.6f}\" for site in site_details]),\n",
    "        \"   :ColumnLocationY    \" + ' '.join([f\"{site['Latitude'] * 60:.6f}\" for site in site_details]),\n",
    "        f\"   :coeff1            {' '.join(['0.0000E+00' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        f\"   :coeff2            {' '.join(['0.0000E+00' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        f\"   :coeff3            {' '.join(['0.0000E+00' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        f\"   :coeff4            {' '.join(['0.0000E+00' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        f\"   :Value1            {' '.join(['1' for _ in range(flow_data.shape[1] - 1)])}\",\n",
    "        \":EndColumnMetaData\",\n",
    "        \":endHeader\"\n",
    "    ]\n",
    "    \n",
    "    # Write header to file\n",
    "    with open(file_path, \"w\") as file_conn:\n",
    "        file_conn.write(\"\\n\".join(header) + \"\\n\")\n",
    "        \n",
    "        # Write data lines, ensuring 24-space padding and equally spaced columns (12.4 format)\n",
    "        for _, row in flow_data.iterrows():\n",
    "            flows = row[1:].values\n",
    "            flow_string = \" \".join(f\"{flow:12.4f}\" for flow in flows)\n",
    "            file_conn.write(f\"{' ' * 22}{flow_string}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "09700c3e-3e8f-4d58-be60-cddc7236e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Define sample lists of station IDs\n",
    "station_ca = [\"05GG001\", \"05AC012\"]\n",
    "station_us = [\"05017500\", \"05020500\"]\n",
    "\n",
    "# Define date range\n",
    "start_date = \"1980-01-01\"\n",
    "end_date = \"2018-01-10\"\n",
    "\n",
    "# Fetch data for the given stations and date range\n",
    "combined_data_ca, station_info_ca = fetch_hydrometric_data_ca(station_ca, start_date, end_date)\n",
    "combined_data_us, station_info_us = extract_flow_data_us(station_us, start_date, end_date)\n",
    "\n",
    "# Combine data into a single DataFrame\n",
    "combined_data = pd.merge(combined_data_ca, combined_data_us, on='Date', how='outer')\n",
    "\n",
    "# Combine station info\n",
    "combined_station_info = station_info_ca + station_info_us\n",
    "\n",
    "# Write the data to a file\n",
    "write_flow_data_to_file_obstxt('output.txt', combined_data, combined_station_info)\n",
    "write_flow_data_to_file_ensim('output_ensim.txt', combined_data, combined_station_info)\n",
    "\n",
    "# Print the resulting DataFrame and station information\n",
    "print(combined_data.head())\n",
    "print(combined_station_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
