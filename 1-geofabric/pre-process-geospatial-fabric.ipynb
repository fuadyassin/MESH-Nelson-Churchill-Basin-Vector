{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b6f999-ca13-4d86-a2e7-1b113b3a1580",
   "metadata": {},
   "source": [
    "# Basic preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95992b8-be42-4339-bc9f-06209234da9b",
   "metadata": {},
   "source": [
    "In this Notebook, the geospatial fabric for the \"Nelson Churchill River Basin\" gauge is extracted from the `MERIT-Basins` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd0062-78ba-43ec-b06d-bcf4fcd2fed3",
   "metadata": {},
   "source": [
    "If you are using Graham HPC, and have access to Clark's Research Group allocation (`rrg-mclark`), you may find `MERIT-Basins` layers under the following path:</br>\n",
    "`/project/rrg-mclark/data/geospatial-data/MERIT-Basins/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f6178-7d12-436b-bba4-d7b86fee3cd2",
   "metadata": {},
   "source": [
    "If you are using Graham HPC, and have access to Global Water Futures Observatories allocation (`rpp-kshook`), you may find `MERIT-Basins` layers under the following path:</br>\n",
    "`/project/rpp-kshook/Climate_Forcing_Data/geospatial-data/MERIT-Basins`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62251bcc-3a44-422e-b90d-4af375051974",
   "metadata": {},
   "source": [
    "The version used is `MERIT_Hydro_v07_Basins_v01_bugfix1` which is a directory under the root directory of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e2ec2-5b46-4d26-a79d-ba594fa69e7f",
   "metadata": {},
   "source": [
    "Let's get started with our workflow and import necessary Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a1237-c037-4eea-9c47-ae35c6f4187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd # version 0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db84867-8c2a-4128-81cd-e34619ee13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # version 1.4.0\n",
    "import numpy as np # version 1.22.2\n",
    "import matplotlib.pyplot as plt # version 3.5.1\n",
    "from shapely.geometry import Point # version 2.0.1\n",
    "import hydrant.topology.geom as gm # version 0.1.0-dev1\n",
    "import subprocess # built-in Python 3.10.2\n",
    "import os # built-in Python 3.10.2\n",
    "import glob # built-in Python 3.10.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524346b-893d-4133-92b5-55f450d472dd",
   "metadata": {},
   "source": [
    "`Hydrant` is important in this Notebook. We are only using the `topology.geom`etry module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e435c67-cb00-4058-b83d-ec1528d1ba9b",
   "metadata": {},
   "source": [
    "Path definitions (system dependant - modify accordingly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c276b-ded3-4baa-8c24-bbed210a20e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# geofabric paths\n",
    "merit_basins_root_path = '/project/6008034/Climate_Forcing_Data/geospatial-data/MERIT-Basins/MERIT_Hydro_v07_Basins_v01_bugfix1'\n",
    "merit_basins_geom_path = os.path.join(merit_basins_root_path, 'pfaf_level_02')\n",
    "merit_basins_nca_path = os.path.join(merit_basins_root_path, 'coastal_hillslopes')\n",
    "# output paths\n",
    "output_path = '/home/fuaday/github-repos/MESH-Nelson-Churchill-Basin-Vector/1-geofabric/ncrb-geofabric/'\n",
    "bs_path = '/home/fuaday/github-repos/MESH-Nelson-Churchill-Basin-Vector/NCRB_shapefiles/NCRB_SubbasinsDissolved.shp'\n",
    "nctr_test = '/home/fuaday/github-repos/MESH-Nelson-Churchill-Basin-Vector/NCRB_shapefiles/non.shp' #ncontr_test.shp\n",
    "nctr_testout = '/home/fuaday/github-repos/MESH-Nelson-Churchill-Basin-Vector/NCRB_shapefiles/ncontr_test2.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbb3a2-c488-47d0-a484-890d6947ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncrb = pd.concat([gpd.read_file(f).to_crs(epsg=4326) for f in glob.glob(bs_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e11473-50ff-4d9f-b759-f555052122c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(nctr_test)\n",
    "\n",
    "# Load files, set CRS, and concatenate\n",
    "gdfs = []\n",
    "for f in files:\n",
    "    gdf = gpd.read_file(f)\n",
    "    if gdf.crs is None:\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "    gdfs.append(gdf.to_crs(epsg=4326))\n",
    "ncrb_nca = pd.concat(gdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb489c-ce70-47ad-bff2-02be455903ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ncrb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bbbdf-c770-43ff-8d5f-a1bbee374e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncrb_nca.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62175c5e-ea00-4dee-a75a-85d1fd505ed5",
   "metadata": {},
   "source": [
    "# Reading `MERIT-Basins` Geospatial Fabric Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b0634-e6eb-42bf-a40d-3e50ad522083",
   "metadata": {},
   "source": [
    "Upon **visual** inspection (you may use `QGIS` or similar programs), layer #71 has been identified to include necessary sub-basins for ncrb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e83da-bc0d-417a-8675-f40828bb5329",
   "metadata": {},
   "source": [
    "As you may see in the cell below, we are using Python `list`s to enable reading multiple layers at once. There are cases where a basin of interest is shared between multiple `pfaf` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a58e0a6-f839-4414-9e63-5a5ab0bcfa45",
   "metadata": {},
   "source": [
    "For now, let's read the files, one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f745271-1067-4d37-915c-87c628a90265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file names\n",
    "# catchments (subbasin)\n",
    "cat_files = [\n",
    "    'cat_pfaf_71_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "]\n",
    "# rivers (river segments)\n",
    "riv_files = [\n",
    "    'riv_pfaf_71_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "]\n",
    "# non-contributing catchments (those without any river segments defined for them)\n",
    "nca_files = [\n",
    "    'hillslope_71_clean.shp',\n",
    "]\n",
    "\n",
    "# reading in data in an iterative manner\n",
    "cat = pd.concat([gpd.read_file(os.path.join(merit_basins_geom_path, f)) for f in cat_files])\n",
    "riv = pd.concat([gpd.read_file(os.path.join(merit_basins_geom_path, f)) for f in riv_files])\n",
    "nca = pd.concat([gpd.read_file(os.path.join(merit_basins_nca_path, f)) for f in nca_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50bb1c-f495-4b4d-850b-1ccbac89a084",
   "metadata": {},
   "source": [
    "Since `MERIT-Basins` layers do not come with correct Coordinate Reference System (CRS) information, we need to specify this manually. The `EPSG` code for the `MERIT-Basins` layer is `4326`. Please refer to the following for more information: https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0b85b-a710-42c3-8a6d-e23a16ae0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying epsg:4326 for all the MERIT-Basins layers\n",
    "cat.set_crs(epsg=4326, inplace=True)\n",
    "nca.set_crs(epsg=4326, inplace=True)\n",
    "riv.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Show the EPSG of all geospatial layers\n",
    "print(f'`cat` CRS: {cat.crs}')\n",
    "print(f'`riv` CRS: {riv.crs}')\n",
    "print(f'`nca` CRS: {nca.crs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f671a-459b-4904-8f5a-cabea3f7fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the sizes\n",
    "print(\"Size of catchments (cat):\", cat.shape)\n",
    "print(\"Size of rivers (riv):\", riv.shape)\n",
    "print(\"Size of non-contributing areas (nca):\", nca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6a889-e215-4111-b65f-8911824cd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the headers of each DataFrame\n",
    "print(\"Header for Catchments (cat):\")\n",
    "print(cat.head())\n",
    "\n",
    "print(\"\\nHeader for Rivers (riv):\")\n",
    "print(riv.head())\n",
    "\n",
    "print(\"\\nHeader for Non-Contributing Areas (nca):\")\n",
    "print(nca.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7704c-bf2e-4b71-9d36-5613d4b3a25b",
   "metadata": {},
   "source": [
    "# Preparing `cat`, `riv`, and `nca` objects for `NCRB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d09b25-eb34-48ac-bc49-eeb92e475b52",
   "metadata": {},
   "source": [
    "## Preparing `MERIT-Basins` Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048cc8d-5c2f-4274-8201-861c7b311d78",
   "metadata": {},
   "source": [
    "Before subsetting the entire layer #71 of the `MERIT-Basins` dataset, we have to assure the layers are ready to be further processed by the `Hydrant` package. Fortunately, `Hydrant` provides necessary functionalities to work with this specific geospatial fabric (applicable to any geospatial fabric in reality). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fd658-5f89-462b-be7c-7af5c39c6d07",
   "metadata": {},
   "source": [
    "In doing so, Hydrant's `geom` module provides the `prepare_cat(...)` function to prepare the `MERIT-Basins` geosptial fabric's sub-basins (or catchments) for the next post-processing steps. Please note that since the non-contributing areas (`nca`) are technically considered sub-basins, they are taken care of using this functionality of `Hydrant`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b9d374-6e79-4ddc-8642-da1505d4a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydrant's `geom` module provides the `prepare_cat`\n",
    "# function to prepare the `MERIT-Basins` geosptial\n",
    "# fabric for next post-processing steps\n",
    "\n",
    "catchments = gm.prepare_cat(\n",
    "    cat=cat, # \n",
    "    cat_col_id='COMID',\n",
    "    cst=nca,\n",
    "    cst_col_mapper={'FID':'COMID'},\n",
    "    cst_col_id='COMID'\n",
    ")\n",
    "\n",
    "# You may see the \"docstring\" of the `gm.prepare_cat`\n",
    "# function by running:\n",
    "# >>> gm.prepare_cat?\n",
    "# in a separate Jupyter cell (without the >>>), or by\n",
    "# running simply:\n",
    "# >>> print(gm.prepare_cat.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69624777-5bbf-4716-b15e-7d69fc37386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added from smm example\n",
    "\n",
    "# first, creating the directory\n",
    "try:\n",
    "    os.makedirs(output_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "catchments.to_file(os.path.join(output_path, 'NCRB_catchmentsTest.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0204da32-fb52-497a-9e38-0ce520d0a32f",
   "metadata": {},
   "source": [
    "Similarly, the `geom` module provides the `prepare_riv(...)` function to prepare the `MERIT-Basins` geospatial fabric's river segments for the next post-processing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471525f-1c5c-452e-81b2-552e5fbf4bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Similarly, the `geom` module provides the\n",
    "# `prepare_riv` function to prepare the `MERIT-Basins`\n",
    "# geospatial fabric's river segments for the next\n",
    "# post-processing steps:\n",
    "\n",
    "rivers = gm.prepare_riv(\n",
    "    riv=riv,\n",
    "    riv_cols={\n",
    "        'id':'COMID',\n",
    "        'next_id':'NextDownID',\n",
    "        'slope':'slope',\n",
    "        'length':'lengthkm',\n",
    "        'length_direct':'lengthdir'\n",
    "    },\n",
    "    cat=catchments,\n",
    "    cat_cols={\n",
    "        'id':'COMID',\n",
    "        'hillslope':'hillslope',\n",
    "        'geom':'geometry'\n",
    "    }\n",
    ")\n",
    "\n",
    "# You may see the \"docstring\" of the `gm.prepare_riv`\n",
    "# function by running:\n",
    "# >>> gm.prepare_riv?\n",
    "# in a separate Jupyter cell (without the >>>), or by\n",
    "# running simply:\n",
    "# >>> print(gm.prepare_riv.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80b0f2-9c8d-4564-9c9c-68bc21ac6676",
   "metadata": {},
   "source": [
    "In Python, you may always access the \"docstring\" documentations for the functions and classes by running:\n",
    "```python\n",
    ">>> print(func.__doc__)\n",
    "```\n",
    "Or, if you are working in the Jupyter environment, you may simply run the following in a separate Jupyter cell:\n",
    "```ipython\n",
    "[ln1] func?\n",
    "```\n",
    "If you are interested in reading up on the functionality of each function used above, use the mentioned methods to print the \"docstrings\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00006a04-7669-4d6f-b14e-da3597708001",
   "metadata": {},
   "source": [
    "Therefore, if you would like to read up on the `gm.prepare_cat(...)` or `gm.prepare_riv(...)` functionality, simply uncomment and execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53761f77-1f33-4195-9dac-82ebbe632b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_gdf = gm.flag_ncaalg(catchments, ncrb_nca,0.3, nctr_testout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5c6dd-214c-4e9b-b69a-0b5d3a2f50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Adjusting global font sizes using rcParams for the plot\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Assuming 'ncrb_catchments' is your GeoDataFrame loaded previously\n",
    "# ncrb_catchments = gpd.read_file('path_to_your_shapefile/ncrb_catchments.shp')\n",
    "\n",
    "# Calculating counts\n",
    "count_1 = ncrb_catchments[ncrb_catchments['ncontr'] == 1].shape[0]\n",
    "count_2 = ncrb_catchments[ncrb_catchments['ncontr'] == 2].shape[0]\n",
    "\n",
    "# Custom colors for the unique values in 'ncontr', assuming they are 1 and 2\n",
    "colors = ['#1f77b4', '#ff7f0e']  # Blue for 1, Orange for 2\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 12))\n",
    "ncrb_catchments.plot(column='ncontr', ax=ax, cmap=cmap, edgecolor=None)\n",
    "\n",
    "# Create a legend with larger font\n",
    "legend_handles = [Patch(color=value_colors[value], label=f'{label} (n={count})') for value, label, count in zip([1, 2], ['1', '2'], [count_1, count_2])]\n",
    "legend = ax.legend(handles=legend_handles, title=\"NCONTR values\", fontsize=14)\n",
    "plt.setp(legend.get_title(), fontsize=14)\n",
    "\n",
    "# Adding text to the plot with counts\n",
    "text_str = f'Count of 1: {count_1}\\nCount of 2: {count_2}'\n",
    "ax.text(0.05, 0.95, text_str, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('ncrb_catchments_plot.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd7732-1149-4721-a63a-15b4f4d2c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncrb_catchments[ncrb_catchments['ncontr'] == 1].shape[0]\n",
    "ncrb_catchments[ncrb_catchments['ncontr'] == 2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d250e0-c0d5-4d0b-8068-a1ea9d443327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gm.prepare_cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c646a-7843-449a-9907-81e0243e18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gm.prepare_riv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10816c5-ac8e-42cb-ad2e-c59759c52068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED from smm example\n",
    "ncrb_catchments, ncrb_rivers = gm.intersect_topology(\n",
    "    cat=modified_gdf,\n",
    "    cat_cols={\n",
    "        'id':'COMID'\n",
    "    },\n",
    "    riv=rivers,\n",
    "    riv_cols={\n",
    "        'id':'COMID',\n",
    "        'next_id':'NextDownID'\n",
    "    },\n",
    "    shapefile=ncrb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe5d21-5e46-4792-8a54-83e5ccaa6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ADDED from smm example\n",
    "# ncrb_catchments, ncrb_rivers = gm.intersect_topology(\n",
    "#     cat=catchments,\n",
    "#     cat_cols={\n",
    "#         'id':'COMID'\n",
    "#     },\n",
    "#     riv=rivers,\n",
    "#     riv_cols={\n",
    "#         'id':'COMID',\n",
    "#         'next_id':'NextDownID'\n",
    "#     },\n",
    "#     shapefile=ncrb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66256271-ffb9-48fc-9606-8b2c00ed8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncrb_catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bcdaa-2bd4-456a-86e1-ebf5b7bfb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ncrb.plot(color='black', alpha=0.3, figsize=(10, 20))\n",
    "#ncrb_rivers.plot(ax=ax, color='red')\n",
    "ncrb_catchments.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629400c3-402e-49fa-ac3d-13fac7956e40",
   "metadata": {},
   "source": [
    "Now, let's plot what have extracted from the larger `MERIT-Basins` geospatial fabric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f3610-f994-4795-91ef-84848c2442a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    figsize=(20, 12)\n",
    ")\n",
    "\n",
    "# Assuming 'ncrb_catchments' and 'ncrb_rivers' are GeoDataFrames and 'point' is a geometry point for the gauge location\n",
    "\n",
    "# sub-basins\n",
    "ncrb_catchments.plot(ax=ax, color='gray', edgecolor='black', alpha=0.8, linewidth=0.3, zorder=1)  # Adjust `linewidth` as needed\n",
    "# river segments\n",
    "ncrb_rivers.plot(ax=ax, color='blue', alpha=1, linewidth=0.3, zorder=2)  # Adjust `linewidth` as needed for rivers\n",
    "\n",
    "# gauge location\n",
    "# Assuming 'point' is defined somewhere above as a geometry point\n",
    "# ax.scatter(point.x, point.y, color='red', alpha=0.8, s=100, zorder=3)  # Use `s` for size in scatter plot, adjust as needed\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a19990-cd78-44d1-94fc-02b70bd830c7",
   "metadata": {},
   "source": [
    "# Saving Extracted Geospatial Fabric upstream of Bow River at Banff Hydrometric Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31015b40-ea8a-49f2-87b6-1eeaed08b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the results into the `output_path` directory\n",
    "\n",
    "# first, creating the directory\n",
    "try:\n",
    "    os.makedirs(output_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# then, saving the data\n",
    "ncrb_catchments.to_file(os.path.join(output_path, 'ncrb_subbasins.shp'))\n",
    "ncrb_rivers.to_file(os.path.join(output_path, 'ncrb_rivers.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e05a57-93f5-4ab7-a75e-a705aea51c1b",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f8793-9913-4983-adb6-ad8a0b5962e2",
   "metadata": {},
   "source": [
    "If you face any issues, e-mail [kasra.keshavarz1 AT ucalgary DOT ca](mailto:kasra.keshavarz1@ucalgary.ca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c354f1-efe2-41ba-b316-9050467db9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "\n",
    "# def assign_intersection_flag_gdf_sindex(\n",
    "#     gdf1: gpd.GeoDataFrame,\n",
    "#     gdf2: gpd.GeoDataFrame,\n",
    "#     threshold: float = 0.1,  # Threshold set to 10% by default\n",
    "#     output_path: str = None\n",
    "# ) -> gpd.GeoDataFrame:\n",
    "#     \"\"\"\n",
    "#     Efficiently assigns a flag to polygons in the first GeoDataFrame based on significant intersection\n",
    "#     (defined by a threshold) with polygons in the second GeoDataFrame using spatial indexing.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     gdf1 : gpd.GeoDataFrame\n",
    "#         The first GeoDataFrame.\n",
    "#     gdf2 : gpd.GeoDataFrame\n",
    "#         The second GeoDataFrame.\n",
    "#     threshold : float, optional\n",
    "#         The threshold for considering an intersection significant, as a fraction of\n",
    "#         the first GeoDataFrame's polygon area (default is 0.1 for 10%).\n",
    "#     output_path : str, optional\n",
    "#         Path where the modified first GeoDataFrame should be saved. If None, the file is not saved.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     gpd.GeoDataFrame\n",
    "#         The modified GeoDataFrame of the first GeoDataFrame with the 'ncontr' column added.\n",
    "#     \"\"\"\n",
    "#     # Initialize the 'ncontr' column to 0 for all rows in gdf1\n",
    "#     gdf1['ncontr'] = 0\n",
    "    \n",
    "#     # Create spatial index for gdf2\n",
    "#     spatial_index = gdf2.sindex\n",
    "    \n",
    "#     # Iterate over gdf1 using spatial indexing to find potential intersections\n",
    "#     for index, row in gdf1.iterrows():\n",
    "#         # Use spatial index to find potential intersections\n",
    "#         possible_matches_index = list(spatial_index.query(row['geometry'], predicate='intersects'))\n",
    "#         if not possible_matches_index:\n",
    "#             continue  # No intersections, move to next row\n",
    "        \n",
    "#         # Filter possible matches for actual intersection\n",
    "#         possible_matches = gdf2.iloc[possible_matches_index]\n",
    "#         actual_intersections = possible_matches[possible_matches.intersects(row['geometry'])]\n",
    "        \n",
    "#         # Calculate area fractions for actual intersections\n",
    "#         for _, match in actual_intersections.iterrows():\n",
    "#             intersection_area = row['geometry'].intersection(match['geometry']).area\n",
    "#             area_fraction = intersection_area / row['geometry'].area\n",
    "#             if area_fraction > threshold:\n",
    "#                 gdf1.at[index, 'ncontr'] = 1\n",
    "#                 break  # Break after finding the first significant intersection\n",
    "    \n",
    "#     # Save the modified gdf1 to a new shapefile if an output path is provided\n",
    "#     if output_path is not None:\n",
    "#         gdf1.to_file(output_path)\n",
    "    \n",
    "#     return gdf1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
